# -*- coding: utf-8 -*-
"""SVHN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k2PqtaCf8y3lQ6w1FhTB5a_70X-Q-oG8

# **SVHN classification using CNN ~ 94% (Format 1)**

## **Imports**

**Mounting Google Drive**
"""

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/My Drive/Colab Notebooks/

"""**Importing libraries**"""

import numpy as np
import seaborn as sns
import pandas as pd
import h5py
import glob
import cv2
import PIL
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import confusion_matrix
from PIL import Image
from skimage.color import rgb2gray
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import SGD
import keras
import keras.utils
from keras import utils as np_utils
from keras.preprocessing.image import ImageDataGenerator

"""## **Reading Image**

**Reading image function**
"""

def read_image(path):
    import cv2
    import os
    import glob
    img_dir = path # Enter Directory of all images 
    data_path = os.path.join(img_dir,'*g')
    files = glob.glob(data_path)
    data = []
    file_names = ["{}{}.png".format(path,i+1) for i in range(len(files))]
    for f1 in file_names:
        image = cv2.imread(f1)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        data.append(image)
        if (len(data)==33401):
            break
        print(len(data),".png",sep="")
    return data

"""**Reading train images**"""

training_dataset = read_image("/content/drive/My Drive/Colab Notebooks/train/")

"""**Reading test images**"""

test_dataset = read_image("/content/drive/My Drive/Colab Notebooks/test/")

"""**Data shaped**"""

print("Length of training dataset: ", len(training_dataset))
print("Length of test datset: ", len(test_dataset))

"""## **Data Visualization**

**Image Visualization**
"""

def plot_image(Image):
    #%pylab inline
    import matplotlib.pyplot as plt
    import matplotlib.image as mpimg
    imgplot = plt.imshow(Image, cmap = "gray")
    plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img= cv2.imread("/content/drive/My Drive/Colab Notebooks/test/1.png")
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

data = []
data.append(img)
imgplot = plt.imshow(img)
plt.show()

"""**Visualize the first ten photos in the training set**"""

for i in range(10):
    plot_image(training_dataset[i])

"""**Visualize the first ten photos in the test set**"""

for i in range(10):
    plot_image(test_dataset[i])

"""## **Data Preprocessing**

**Defining functions to get pic names and bounding boxes info from .mat file**
"""

def get_name(f, index=0):
    name = f['/digitStruct/name']
    return ''.join([chr(v[0]) for v in f[(name[index][0])]])


def get_bbox(f, index=0):
     meta = { key : [] for key in ['height', 'left', 'top', 'width', 'label']}
     def print_attrs(name, obj):
        vals = []
        if obj.shape[0] == 1:
            vals.append(int(obj[0][0]))
        else:
            for k in range(obj.shape[0]):
                vals.append(int(f[obj[k][0]][0][0]))
        meta[name] = vals
     box = f['/digitStruct/bbox'][index]
     f[box[0]].visititems(print_attrs)
     return meta

"""**Getting train set's name and bbox data + cropping images**"""

def crop_image(path, dataset, label_dataset, X, Y):
    data_name = []
    data_bbox = []
    size = len(dataset)
    with h5py.File(path, 'r') as folder_data:
        # Getting data
        for i in range(size):
            data_name.append(get_name(folder_data, i))
            data_bbox.append(get_bbox(folder_data, i))
            print(data_name[i])
            # Cropping current image
            cropped = []
            label = []
            for k in range(len(data_bbox[i]['top'])):
                top = data_bbox[i]['top'][k]
                left = data_bbox[i]['left'][k]
                height = data_bbox[i]['height'][k]
                width = data_bbox[i]['width'][k]
                image = dataset[i][top:top+height,left:left+width]
                if (image.shape[0]==0 or image.shape[1]==0):
                    continue;
                label.append(data_bbox[i]['label'][k])
                cropped.append(dataset[i][top:top+height,left:left+width])
                X.append(dataset[i][top:top+height,left:left+width])
                Y.append(data_bbox[i]['label'][k])
            dataset[i] = cropped
            label_dataset.append(label)

"""**Crop image in training dataset**"""

label_training_dataset = []
X_train = []
Y_train = []
crop_image('/content/drive/My Drive/Colab Notebooks/train_digitStruct.mat', training_dataset, label_training_dataset, X_train, Y_train)

"""**Crop image in test dataset**"""

label_test_dataset = []
X_test = []
Y_test = []
crop_image('/content/drive/My Drive/Colab Notebooks/test_digitStruct.mat', test_dataset, label_test_dataset, X_test, Y_test)

"""**Visualize images on cropping**"""

for i in range(5):
    plot_image(X_train[i])

"""**Find minimum and maximum of height and width all images**"""

min_image_size = 999999999
max_image_size = 0
for i in range(0,len(X_train)):
    height = X_train[i].shape[0]
    width = X_train[i].shape[1]
    min_image_size = min(min(min_image_size, height), width)
    max_image_size = max(max(max_image_size, height), width)
print("Min image size: ",min_image_size)
print("Max image size: ",max_image_size)

"""**Convert RGB color to Gray Scale**"""

for i in range(0, len(X_train)):
    X_train[i] = rgb2gray(X_train[i])

for i in range(0,len(X_test)):
    X_test[i] = rgb2gray(X_test[i])

"""**Visualize image after converting to GRAY SCALE**"""

for i in range(5):
    plot_image(X_train[i])

"""**Check faulty image and resize images to the same size**"""

image_size = (32,32)
invalid_frame = []
for i in range(0, len(X_train)):
    try:
        X_train[i] = cv2.resize(X_train[i], image_size)
    except cv2.error as e:
        print('Invalid frame!',i)
        invalid_frame.append(i)
        print(X_train[i].shape)
    cv2.waitKey()
for i in range(0,len(invalid_frame)):
    X_train.pop(invalid_frame[i]-i)
    Y_train.pop(invalid_frame[i]-i)

invalid_frame = []
for i in range(0, len(X_test)):
    try:
        X_test[i] = cv2.resize(X_test[i], image_size)
    except cv2.error as e:
        print('Invalid frame!',i)
        invalid_frame.append(i)
        print(X_test[i].shape)
    cv2.waitKey()
for i in range(0,len(invalid_frame)):
    X_test.pop(invalid_frame[i]-i)
    Y_test.pop(invalid_frame[i]-i)

"""**Convert training image list to numpy array**"""

X_train = numpy.array(X_train)
Y_train = numpy.array(Y_train)

X_test = numpy.array(X_test)
Y_test = numpy.array(Y_test)

"""**Fit and transform the label values to a one-hot-encoding scheme (ready for CNN)**"""

enc = OneHotEncoder(sparse=False)
Y_train = enc.fit_transform(Y_train.reshape(-1,1))

Y_test = enc.transform(Y_test.reshape(-1,1))

"""**X and Y shapes after preprocessing**"""

X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.15, random_state=42)

print("Training set: ", X_train.shape, Y_train.shape)
print("Validation set: ", X_val.shape, Y_val.shape)
print("Test set: ", X_test.shape, Y_test.shape)

"""**Reshape X from 3 dimensions to 4 dimensions (ready for CNN)**"""

X_train = X_train.reshape(-1,image_size[0],image_size[1],1)
X_test = X_test.reshape(-1,image_size[0],image_size[1],1)
X_val = X_val.reshape(-1,image_size[0],image_size[1],1)

"""## **Setting and Training Model**"""

datagen = ImageDataGenerator(rotation_range=8,
                             zoom_range=[0.95, 1.05],
                             height_shift_range=0.10,
                             shear_range=0.15)

keras.backend.clear_session()

model = keras.Sequential([
    keras.layers.Conv2D(32, (3, 3), padding='same', 
                           activation='relu',
                           input_shape=(image_size[0], image_size[1], 1)),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(32, (3, 3), padding='same', 
                        activation='relu'),
    keras.layers.MaxPooling2D((2, 2)),
    keras.layers.Dropout(0.3),
    

    keras.layers.Conv2D(64, (3, 3), padding='same', 
                           activation='relu'),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(64, (3, 3), padding='same',
                        activation='relu'),
    keras.layers.MaxPooling2D((2, 2)),
    keras.layers.Dropout(0.3),
    

    keras.layers.Conv2D(128, (3, 3), padding='same', 
                           activation='relu'),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(128, (3, 3), padding='same',
                        activation='relu'),
    keras.layers.MaxPooling2D((2, 2)),
    keras.layers.Dropout(0.3),
    
    
    keras.layers.Flatten(),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dropout(0.4),    
    keras.layers.Dense(10,  activation='softmax')
])

early_stopping = keras.callbacks.EarlyStopping(patience=8)
optimizer = keras.optimizers.Adam(amsgrad=True)
model_checkpoint = keras.callbacks.ModelCheckpoint('best_cnn.h5', 
                   save_best_only=True)
model.compile(optimizer=optimizer,
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=128),
                              epochs=50, validation_data=(X_val, Y_val),
                              callbacks=[early_stopping, model_checkpoint])

"""## **Visualizations and insights**

**Evaluate train and validation accuracies and losses**
"""

train_acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

train_loss = history.history['loss']
val_loss = history.history['val_loss']

"""**Visualize epochs vs. train and validation accuracies and losses**"""

plt.figure(figsize=(20, 10))

plt.subplot(1, 2, 1)
plt.plot(train_acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend()
plt.title('Epochs vs. Training and Validation Accuracy')
    
plt.subplot(1, 2, 2)
plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend()
plt.title('Epochs vs. Training and Validation Loss')

plt.show()

"""**Get predictions and apply inverse transformation to the labels**"""

Y_pred = model.predict(X_train)
Y_pred = enc.inverse_transform(Y_pred)
Y_train = enc.inverse_transform(Y_train)

"""**Plot the confusion matrix for training set**"""

plt.figure(dpi=300)
cm = confusion_matrix(Y_train, Y_pred)
plt.title('Confusion matrix for training set', weight='bold')
sns.heatmap(cm,annot=True,fmt='g',cmap='coolwarm',annot_kws={"size": 12})
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""## **Model Evaluation**

**Evaluate model on test set**
"""

test_loss, test_acc = model.evaluate(x=X_test, y=Y_test, verbose=0)

print('Test accuracy is: {:0.4f} \nTest loss is: {:0.4f}'.
      format(test_acc, test_loss))

"""**Evaluate character accuracy on test set**"""

Y_pred = model.predict(X_test)
Y_pred = enc.inverse_transform(Y_pred)
Y_test = enc.inverse_transform(Y_test)
print(classification_report(Y_test, Y_pred))

def accuracy_multi(dataset,label_dataset, Y_true, Y_pred):
    count_image_recognized_correctly = 0
    F = []
    F.append(len(label_dataset[0]))
    for i in range(len(label_dataset)):
        if (i>0):   
            F.append(F[i-1]+len(label_dataset[i]))
        Check = True;
        for k in range(len(label_dataset[i])):
            if (i>0):
                p = F[i-1]+k
            else:
                p = 0
            if (Y_pred[p][0]!=Y_true[p][0]):
                Check = False
                break
                #print(i,Y_pred[p][0],Y_true[p][0])
        if (Check==True):
            count_image_recognized_correctly += 1
    return count_image_recognized_correctly/len(test_dataset)

"""**Evaluate sequence accuracy all images on test set**"""

print("Test image accuracy: ",accuracy_multi(test_dataset, label_test_dataset, Y_test, Y_pred))
